{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import artm\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\NIVC\\\\Nivc_BigARTM_corpus\\\\unary_comm\\\\'\n",
    "subd = \"islamreviewru\"\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path=path + \"\\\\\" + subd + \"\\\\\" + \"batches_pos\",\n",
    "                                            data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelARTM = artm.ARTM(topic_names=['topic_{}'.format(i) for i in xrange(100)],\n",
    "                      scores=[artm.PerplexityScore(name='PerplexityScore', use_unigram_document_model=False, \n",
    "                                                   dictionary=batch_vectorizer.dictionary, class_ids=[\"text\"]),\n",
    "                              artm.SparsityPhiScore(name='SparsityPhiScore', class_id=\"text\"),\n",
    "                              artm.SparsityThetaScore(name='SparsityThetaScore'),\n",
    "                              artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3, class_id=\"text\"),\n",
    "                              artm.TopTokensScore(name='TopTokensScore', num_tokens=100, class_id=\"text\")], \n",
    "                      cache_theta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelARTM.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-1))\n",
    "modelARTM.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1,class_ids=[\"text\"]))\n",
    "modelARTM.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5, class_ids=[\"text\"]))\n",
    "modelARTM.regularizers.add(artm.ImproveCoherencePhiRegularizer(name='CoherencePhi', tau=0.1, class_ids=[\"text\"]))\n",
    "modelARTM.regularizers.add(artm.TopicSelectionThetaRegularizer(name='TopicSelectionTheta', tau=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelARTM.initialize(dictionary=batch_vectorizer.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelARTM.load(filename=path+subd+\"\\\\ARTM_model\\\\\"+subd+\".n_wt.model\",model_name='n_wt')\n",
    "modelARTM.load(filename=path+subd+\"\\\\ARTM_model\\\\\"+subd+\".p_wt.model\",model_name='p_wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelARTM.num_document_passes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelARTM.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================ARTM PerplexityScore start====================================\n[773.6142049153408]\n===========================ARTM PerplexityScore end======================================\n"
     ]
    }
   ],
   "source": [
    "print \"===========================ARTM PerplexityScore start====================================\"\n",
    "print modelARTM.score_tracker['PerplexityScore'].value\n",
    "print \"===========================ARTM PerplexityScore end======================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======save ARTM topics========\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "print \"======save ARTM topics========\"\n",
    "with io.open(path+subd+\"\\\\ARTM_topics\"+'\\\\100.topics','w',encoding='utf8') as outputTopics:\n",
    "    try:\n",
    "        outputTopics.write(u'{\\n')\n",
    "        j = 0\n",
    "        #topic_names = [key for key in modelPLSA.score_tracker['TopTokensScore'].last_tokens]\n",
    "        for topic_name in modelARTM.topic_names:\n",
    "            #print topic_name + \"\\n\"\n",
    "            outputTopics.write(u\"\\\"\"+unicode(topic_name + u'\\\": '))\n",
    "            outputTopics.write(u\"{\")\n",
    "            i = 0\n",
    "            lenTopic = len(modelARTM.score_tracker['TopTokensScore'].last_tokens[topic_name])-1\n",
    "            topicWords = modelARTM.score_tracker['TopTokensScore'].last_tokens[topic_name]\n",
    "            topicWeights = modelARTM.score_tracker['TopTokensScore'].weights[0][topic_name]\n",
    "            for word in topicWords:\n",
    "                #print word + \"\\n\"\n",
    "                outputTopics.write(u\"\\\"\"+unicode(word)+u\"\\\": \"+unicode(str(topicWeights[i])))\n",
    "                if i != lenTopic:\n",
    "                    outputTopics.write(u\",\\n\")\n",
    "                i += 1\n",
    "            outputTopics.write(u\"}\")\n",
    "            if j != len(modelARTM.topic_names)-1:\n",
    "                outputTopics.write(u\",\\n\")\n",
    "            j += 1\n",
    "        outputTopics.write(u\"\\n}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    outputTopics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLSA = artm.ARTM(topic_names=['topic_{}'.format(i) for i in xrange(100)],\n",
    "                      scores=[artm.PerplexityScore(name='PerplexityScore', use_unigram_document_model=False,\n",
    "                                                   dictionary=batch_vectorizer.dictionary, class_ids=[\"text\"]),\n",
    "                              artm.SparsityPhiScore(name='SparsityPhiScore', class_id=\"text\"),\n",
    "                              artm.SparsityThetaScore(name='SparsityThetaScore'),\n",
    "                              artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3, class_id=\"text\"),\n",
    "                              artm.TopTokensScore(name='TopTokensScore', num_tokens=100, class_id=\"text\")],\n",
    "                      cache_theta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLSA.initialize(dictionary=batch_vectorizer.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLSA.load(filename=path+subd+\"\\\\PLSA_model\\\\\"+subd+\".p_wt.model\",model_name='p_wt')\n",
    "modelPLSA.load(filename=path+subd+\"\\\\PLSA_model\\\\\"+subd+\".n_wt.model\",model_name='n_wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLSA.num_document_passes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLSA.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================PLSA PerplexityScore start====================================\n[769.5730824969903]\n===========================PLSA PerplexityScore end======================================\n"
     ]
    }
   ],
   "source": [
    "print \"===========================PLSA PerplexityScore start====================================\"\n",
    "print modelPLSA.score_tracker['PerplexityScore'].value\n",
    "print \"===========================PLSA PerplexityScore end======================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======save PLSA topics========\n"
     ]
    }
   ],
   "source": [
    "print \"======save PLSA topics========\"\n",
    "with io.open(path+subd+\"\\\\PLSA_topics\"+'\\\\100.topics','w',encoding='utf8') as outputTopics:\n",
    "    try:\n",
    "        outputTopics.write(u'{\\n')\n",
    "        j = 0\n",
    "        #topic_names = [key for key in modelPLSA.score_tracker['TopTokensScore'].last_tokens]\n",
    "        for topic_name in modelPLSA.topic_names:\n",
    "            #print topic_name + \"\\n\"\n",
    "            outputTopics.write(u\"\\\"\"+unicode(topic_name + u'\\\": '))\n",
    "            outputTopics.write(u\"{\")\n",
    "            i = 0\n",
    "            lenTopic = len(modelPLSA.score_tracker['TopTokensScore'].last_tokens[topic_name])-1\n",
    "            topicWords = modelPLSA.score_tracker['TopTokensScore'].last_tokens[topic_name]\n",
    "            topicWeights = modelPLSA.score_tracker['TopTokensScore'].weights[0][topic_name]\n",
    "            for word in topicWords:\n",
    "                #print word + \"\\n\"\n",
    "                outputTopics.write(u\"\\\"\"+unicode(word)+u\"\\\": \"+unicode(str(topicWeights[i])))\n",
    "                if i != lenTopic:\n",
    "                    outputTopics.write(u\",\\n\")\n",
    "                i += 1\n",
    "            outputTopics.write(u\"}\")\n",
    "            if j != len(modelPLSA.topic_names)-1:\n",
    "                outputTopics.write(u\",\\n\")\n",
    "            j += 1\n",
    "        outputTopics.write(u\"\\n}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    outputTopics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}